import argparse
import cv2
import os
import torch
import torch.nn as nn
import numpy as np
from tqdm import tqdm

from model import DINOv3Segmentation, hidden_size
from config import ALL_CLASSES
from utils import (
    image_overlay,
    get_segment_labels,
    safe_torch_load,
    calculate_dinov3_dimensions
)


def process_mask_to_fill_holes(mask, width, height):
    """
    æ”¹è¿›ç‰ˆå¡«å……ç®—æ³•ï¼šç§»é™¤å‡¸åŒ…ï¼Œä½¿ç”¨å½¢æ€å­¦é—­è¿ç®—å’Œå¤šè¾¹å½¢æ‹Ÿåˆã€‚
    ä¿ç•™å¹¿å‘Šç‰Œçš„é€è§†å½¢çŠ¶å’Œå‡¹é™·åŒºåŸŸï¼Œé¿å…åŒ…è£¹èƒŒæ™¯ã€‚
    """
    # 1. è°ƒæ•´åˆ°åŸå§‹å°ºå¯¸
    mask_resized = cv2.resize(mask, (width, height), interpolation=cv2.INTER_NEAREST)

    # 2. å®šä¹‰å½¢æ€å­¦æ“ä½œæ ¸
    # ç­–ç•¥è°ƒæ•´ï¼šä¸å†ä¾èµ–å‡¸åŒ…æ¥å¡«å……ï¼Œè€Œæ˜¯é€šè¿‡â€œé—­è¿ç®—â€è®©ç©ºå¿ƒçš„æ¡†å˜æˆå®å¿ƒçš„æ¡

    # çºµå‘æ ¸ (Kernel Vertical): å…³é”®å‚æ•°
    # é«˜åº¦è®¾å¾—è¾ƒå¤§ (ä¾‹å¦‚ 50-80)ï¼Œç”¨äºå¡«æ»¡å¹¿å‘Šç‰Œä¸Šä¸‹è¾¹ç¼˜ä¹‹é—´çš„ç©ºéš™
    # å®½åº¦è®¾å¾—è¾ƒå° (ä¾‹å¦‚ 3-5)ï¼Œé˜²æ­¢å·¦å³æ–¹å‘è¯¯è¿
    kv_height = int(height * 0.08)  # åŠ¨æ€è®¡ç®—ï¼Œçº¦ä¸ºå±å¹•é«˜åº¦çš„ 8%
    kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (3, kv_height))

    # æ¨ªå‘æ ¸ (Kernel Horizontal):
    # ç”¨äºè¿æ¥æ¨ªå‘æ–­è£‚çš„æ–‡å­—æˆ–çº¹ç†
    kh_width = int(width * 0.05)  # åŠ¨æ€è®¡ç®—ï¼Œçº¦ä¸ºå±å¹•å®½åº¦çš„ 5%
    kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (kh_width, 3))

    # 3. å½¢æ€å­¦æ“ä½œæµç¨‹
    # æ­¥éª¤A: çºµå‘é—­è¿ç®— (Closing)
    # è¿™ä¸€æ­¥æ˜¯æ ¸å¿ƒï¼šå®ƒä¼šå°†ä¸Šä¸‹ä¸¤æ ¹çº¿â€œå¸â€åœ¨ä¸€èµ·ï¼Œå˜æˆå®å¿ƒåŒºåŸŸï¼Œä½†ä¸ä¼šæ”¹å˜å·¦å³è½®å»“
    mask_processed = cv2.morphologyEx(mask_resized, cv2.MORPH_CLOSE, kernel_v)

    # æ­¥éª¤B: æ¨ªå‘é—­è¿ç®—
    # è¿æ¥æ–­å¼€çš„æ®µè½
    mask_processed = cv2.morphologyEx(mask_processed, cv2.MORPH_CLOSE, kernel_h)

    # æ­¥éª¤C: ç¨å¾®è†¨èƒ€ä¸€ç‚¹ç‚¹ï¼Œå¼¥è¡¥è¾¹ç¼˜çš„é”¯é½¿
    kernel_smooth = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    mask_processed = cv2.dilate(mask_processed, kernel_smooth, iterations=1)

    # 4. è½®å»“æŸ¥æ‰¾ä¸å¤šè¾¹å½¢æ‹Ÿåˆ (æ›¿ä»£å‡¸åŒ…)
    cnts, _ = cv2.findContours(mask_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    filled_mask = np.zeros_like(mask_resized)

    for c in cnts:
        # è¿‡æ»¤å™ªå£°
        if cv2.contourArea(c) < 3000:
            continue

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨ approxPolyDP æ›¿ä»£ convexHull ---
        # epsilon æ˜¯æ‹Ÿåˆç²¾åº¦ï¼Œå€¼è¶Šå°è¶Šè´´åˆåŸè½®å»“ï¼Œå€¼è¶Šå¤§è¶Šå¹³æ»‘
        # 0.005 * å‘¨é•¿ æ˜¯ä¸€ä¸ªç»éªŒå€¼ï¼Œæ—¢èƒ½ä¿æŒç›´çº¿ç‰¹å¾ï¼Œåˆèƒ½ä¿ç•™å¼¯æ›²/é€è§†å˜åŒ–
        epsilon = 0.005 * cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, epsilon, True)

        # ç»˜åˆ¶å¡«å……çš„å¤šè¾¹å½¢
        # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥ç”» approxï¼Œå®ƒå…è®¸å‡¹å¤šè¾¹å½¢ (Concave)ï¼Œ
        # æ‰€ä»¥è‰åªå¦‚æœæœ¬æ¥å°±æ²¡è¢«å½¢æ€å­¦å·è¿›å»ï¼Œè¿™é‡Œä¹Ÿä¸ä¼šè¢«ç”»è¿›å»
        cv2.drawContours(filled_mask, [approx], -1, 1, -1)

    return filled_mask


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', default='input/videos/cut_video.mp4', help='path to input video file')
    parser.add_argument('--output', default='outputs/cut_result_filled_4.mp4', help='path to save output video')
    parser.add_argument('--model', default='outputs/kaggle_model_896/best_model_iou.pth', help='path to trained model')
    parser.add_argument('--imgsz', type=int, nargs='+', default=[896, 896], help='inference size (width height)')
    parser.add_argument('--device', default='cuda:0', help='cuda or cpu')
    args = parser.parse_args()

    # 2. åˆå§‹åŒ–è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() and args.device != 'cpu' else 'cpu')
    print(f"ğŸš€ Using device: {device}")

    # 3. åŠ è½½æ¨¡å‹
    model = DINOv3Segmentation()
    # é‡æ–°åˆå§‹åŒ–åˆ†å‰²å¤´
    model.decode_head.conv_seg = nn.Conv2d(hidden_size, len(ALL_CLASSES), kernel_size=(1, 1))

    print(f"ğŸ“¥ Loading model from {args.model}...")
    ckpt = safe_torch_load(args.model, map_location=device)
    model.load_state_dict(ckpt['model_state_dict'])
    model.to(device).eval()

    # 4. è§†é¢‘è®¾ç½®
    cap = cv2.VideoCapture(args.input)
    if not cap.isOpened():
        print(f"âŒ Error opening video file {args.input}")
        return

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # è®¡ç®—æ¨ç†å°ºå¯¸
    req_w, req_h = args.imgsz[0], args.imgsz[1]
    infer_w, infer_h = calculate_dinov3_dimensions(req_w, req_h)
    print(f"ğŸ“ Inference size: {infer_w}x{infer_h} (Original: {width}x{height})")

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(args.output, fourcc, fps, (width, height))

    print("ğŸ¬ Starting inference with Region Filling...")
    pbar = tqdm(total=total_frames)

    frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # é¢„å¤„ç†
        frame_resized = cv2.resize(frame, (infer_w, infer_h))
        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)

        # æ¨ç†
        current_size = [infer_w, infer_h]
        labels = get_segment_labels(frame_rgb, model, device, current_size)

        # --- ç»´åº¦å¤„ç† ---
        labels = labels.squeeze()
        mask = labels.cpu().numpy().astype(np.uint8)
        while mask.ndim > 2:
            mask = mask[0]

        # ---------------------------------------------------------
        # ğŸ› ï¸ æ™ºèƒ½å¡«å……ç®—æ³•
        # ç›´æ¥åœ¨ mask å±‚çº§è¿›è¡Œå¡«å……ï¼Œè€Œä¸æ˜¯ resize ä¹‹åå†ç”»æ¡†
        # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥ 0/1 çš„ maskï¼Œç´¢å¼• 1 æ˜¯å¹¿å‘Šç‰Œç±»åˆ«
        # ---------------------------------------------------------

        # æå–å¹¿å‘Šç‰Œ mask (ç±»åˆ«ç´¢å¼• 1 æ˜¯å¹¿å‘Šç‰Œï¼Œå¦‚æœæ˜¯å…¶ä»–ç±»åˆ«è¯·ä¿®æ”¹æ­¤å¤„)
        binary_mask = (mask == 1).astype(np.uint8)

        # å¦‚æœç”»é¢ä¸­æœ‰æ£€æµ‹åˆ°å†…å®¹æ‰å¤„ç†
        if np.any(binary_mask):
            # è°ƒç”¨å¡«å……å‡½æ•°ï¼Œå¾—åˆ°å¡«å……åçš„å®Œæ•´ Mask (å°ºå¯¸ä¸º width x height)
            filled_mask = process_mask_to_fill_holes(binary_mask, width, height)

            # ç”Ÿæˆç»¿è‰²é®ç½©
            color_mask = np.zeros_like(frame)
            mask_bool = (filled_mask == 1)

            # åº”ç”¨é®ç½©
            if np.any(mask_bool):
                color_mask[mask_bool] = [0, 255, 0]  # ç»¿è‰²
                alpha = 0.5
                frame[mask_bool] = cv2.addWeighted(frame[mask_bool], 1 - alpha, color_mask[mask_bool], alpha, 0)

        # ---------------------------------------------------------

        out.write(frame)
        pbar.update(1)
        frame_count += 1

    cap.release()
    out.release()
    print(f"\nâœ… Video saved to {args.output}")


if __name__ == '__main__':
    main()
